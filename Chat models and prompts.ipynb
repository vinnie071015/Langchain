{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a9d2fe4-2a30-4520-ad71-3589ca52a56a",
   "metadata": {},
   "source": [
    "# 项目地址  \n",
    "https://python.langchain.com/docs/tutorials/llm_chain/\n",
    "\n",
    "通过这个项目，你将获得的能力：  \n",
    "1.使用大语言模型  \n",
    "2.使用提示词模版  \n",
    "3.使用LangSmith来调试和追踪你的应用问题  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c1c638-2502-4842-bce5-924a53d36395",
   "metadata": {},
   "source": [
    "# 代码环境设置\n",
    "Jupyter Notebook or Jupyter Lab\n",
    "自行找文档下载安装哈"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f12822b-bbbb-4231-abfe-bd69a517a765",
   "metadata": {},
   "source": [
    "## 安装langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5e742a-22c2-42c2-a7cd-8446cbc06933",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.1' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb97dc3-7cf4-45ce-b105-12f1dcf2a6c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.1' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf39aff6-ee88-490e-9c11-7f0b5e3ba7d9",
   "metadata": {},
   "source": [
    "# 设置Langsmith\n",
    "1. LangSmith是做什么的  \n",
    "    - 跟踪调试：记录模型运行过程，定位问题。\n",
    "    - 测试评估：批量测试模型表现，支持自定义标准。\n",
    "    - 实时监控：跟踪生产环境性能和用户交互。\n",
    "    - Prompt 管理：优化和管理提示词，支持版本控制。  \n",
    "    \n",
    "2. Address：\n",
    "    https://smith.langchain.com/onboarding?organizationId=d33de966-2acd-4e99-884a-4a51a8600109&step=1\n",
    "3. 其他:\n",
    "    - 需要注册\n",
    "    - 需要生成API key用来交互，服务在云端\n",
    "    - 如没有监控需求，也可以选择不启用这个监控服务，对后续无影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a359b86d-a3f4-4033-b94c-99b4fc45ddeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.1' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# 代码\n",
    "\n",
    "import getpass\n",
    "import os  \n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4300e2-cc7c-417d-ad63-b1f6ca313f62",
   "metadata": {
    "tags": []
   },
   "source": [
    "**代码解释**\n",
    "1. getpass：getpass 是一个用于安全输入密码或敏感信息的工具。它的主要功能是让用户在终端输入内容时不回显（即输入时不会显示字符，通常用于密码输入）。\n",
    "2. os：os 模块提供了与操作系统交互的功能，包括文件操作、路径处理和环境变量管理等。\n",
    "3. os.environ[\"LANGSMITH_TRACING\"] = \"true\" 用来激活LangSmith服务，在后续的Langchain模块中会检测这个环境变量是否启用，如果启用会和LangSmith服务进行交互进而开启监控。\n",
    "4. os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()\n",
    "    1. 用来拿到LangSmith的API Key\n",
    "    2. getpass.getpass() 会提示用户在终端输入内容（默认提示是 \"Password: \"），输入的内容不会显示在屏幕上\n",
    "    3. Appkey需要注册账号，然后在网站内生成即可，也可以选择不启用这个监控服务，跳过即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d321239e-841b-4a14-b60c-0ec87097adc9",
   "metadata": {},
   "source": [
    "## 使用大语言模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6a0cda-94d3-435e-bc44-21eb24902de8",
   "metadata": {},
   "source": [
    "**安装langchain的集成**  \n",
    "pip install -qU \"langchain-deepseek\"\n",
    "\n",
    "- 安装Deepseek的Langchain扩展，用于和Deepseek接口进行交互。\n",
    "- Langchain也可以使用其他的模型，具体请直接查询官方文档代码，集成会有不一样，代码会有所变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560e98a2-6be7-4d33-be7d-76c8e148280d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.1' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# 配置接口参数，创建语言模型的实例\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",  # 指定使用的模型\n",
    "    temperature=0,  # 控制生成文本的随机性\n",
    "    max_tokens=None,  # 生成的最大 token 数限制\n",
    "    timeout=None,  # 请求超时时间\n",
    "    max_retries=2, # 请求失败时的最大重试次数\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79006fa1-141d-4bf9-a19e-b81dabc1be4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.1' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# 前置需要进入deepseek官网注册并生成API_KEY，记得保存好，否则丢失后需要重新生成。\n",
    "# 这一行检查程序是否已经有 Deepseek API 密钥。如果没有，就需要用户手动输入。\n",
    "if not os.getenv(\"DEEPSEEK_API_KEY\"):\n",
    "    os.environ[\"DEEPSEEK_API_KEY\"] = getpass.getpass(\"Enter your DeepSeek API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b69249-e219-4cba-83c8-cc80f0894a31",
   "metadata": {},
   "source": [
    "**代码解释**\n",
    "- os.getenv(key) 是 os 模块的一个函数，用于读取环境变量的值。\n",
    "- 如果环境变量 DEEPSEEK_API_KEY 已设置（比如通过终端的 export DEEPSEEK_API_KEY=\"your-key\"），它返回对应的值（字符串）。\n",
    "- 如果未设置或值为空，则返回 None。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582e5462-c338-45ee-ab1e-964f1552bc0e",
   "metadata": {},
   "source": [
    "## 流式处理stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82b1656a-bd61-4ac0-bb52-5c498545db1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"J'adore la programmation.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b087e90-7de1-4851-8fad-e1faa66b63a5",
   "metadata": {},
   "source": [
    "**代码解释**\n",
    "- 定义一个列表 messages，包含两条消息，每条消息是一个元组 (角色, 内容)。\n",
    "- 调用语言模型（llm）的 invoke 方法，将 messages 作为输入，生成响应，并将结果赋值给 ai_msg。\n",
    "- 访问 ai_msg 对象的 content 属性，获取模型生成的文本内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c19c95a-6eef-4a94-aaeb-a78508485e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|J|'ad|ore| programmer|.||"
     ]
    }
   ],
   "source": [
    "for token in llm.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32738cc5-9c5c-4830-9376-5d96e58a3c7f",
   "metadata": {},
   "source": [
    "**代码解释**\n",
    "- 通过 llm.stream(messages) 调用语言模型的流式输出方法，并用 for 循环迭代处理返回的每个 token。\n",
    "- stream 是语言模型提供的一个方法，用于以流式（streaming）方式生成输出。\n",
    "- 与一次性返回完整结果的 invoke 不同，stream 返回一个迭代器（iterator）或生成器（generator），逐步生成并返回模型输出的每个 token。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b101c7d7-244e-450e-b0b9-2a9ef55d71cf",
   "metadata": {},
   "source": [
    "## 提示词模版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "422d9fd8-2d79-42b4-b96e-c7567280903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个提示模板，用于将用户输入的英文文本翻译成指定语言并传递给大模型。\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following from English into {language}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ea336e-9d68-4429-8823-4932f4abf60b",
   "metadata": {},
   "source": [
    "**代码解释**\n",
    "- ChatPromptTemplate 是 LangChain 提供的一个工具，用于构建结构化的对话提示模板。\n",
    "- 它特别适合与支持聊天格式的语言模型（如 ChatDeepSeek、ChatOpenAI）配合使用，允许定义多角色消息（如系统消息、用户消息）。\n",
    "- prompt_template 是一个可重用的模板对象，允许动态填入 {language} 和 {text} 的值，生成完整的提示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dc1a287-6141-4005-bf71-066bde850529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({\"language\": \"Italian\", \"text\": \"hi!\"})\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fdafc7-1d15-4ce9-b235-daf4942ef727",
   "metadata": {},
   "source": [
    "**代码解释**\n",
    "- invoke 是 ChatPromptTemplate 的方法，用于将占位符替换为具体值，生成一个具体的提示对象。\n",
    "- 输入是一个字典，键（language 和 text）对应模板中的占位符，值（\"Italian\" 和 \"hi!\"）是替换的内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ebb8121-5991-495e-8a36-a1868e21cef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940b55aa-1431-4a6d-b37b-6afe3f23441d",
   "metadata": {},
   "source": [
    "**代码解释**\n",
    "- 调用 prompt 对象的 to_messages() 方法，返回一个消息列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b4e18e1-6d3c-4820-89fd-3a747d6816c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciao!\n"
     ]
    }
   ],
   "source": [
    "#与大模型交互，将提示词模版传输给大模型，并得到答案\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4414cfc-42f9-4c40-9fe5-87ae7b904420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
